{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Python Cheat Sheet.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZRtyBhhk6Ms",
        "colab_type": "text"
      },
      "source": [
        "# Kaggle Kernel Cheat Sheet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jog1hpZqk_5F",
        "colab_type": "text"
      },
      "source": [
        "Here is the cheat sheet for  code used by Will Koehrsen, for his Kaggle kernel, which can be found at: \n",
        "https://www.kaggle.com/willkoehrsen/start-here-a-gentle-introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjQOUG44vhHi",
        "colab_type": "text"
      },
      "source": [
        "##**Finding the Percentage of Missing and Max Values for Each Column**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtmuzchOvovz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stats = []\n",
        "for col in train.columns:\n",
        "    stats.append((col, train[col].nunique(), train[col].isnull().sum() * 100 / train.shape[0], train[col].value_counts(normalize=True, dropna=False).values[0] * 100, train[col].dtype))\n",
        "    \n",
        "stats_df = pd.DataFrame(stats, columns=['Feature', 'Unique_values', 'Percentage of missing values', 'Percentage of values in the biggest category', 'type'])\n",
        "stats_df.sort_values('Percentage of missing values', ascending=False)\n",
        "\n",
        "#https://www.kaggle.com/artgor/is-this-malware-eda-fe-and-lgb-updated"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTou3SKyv0c-",
        "colab_type": "text"
      },
      "source": [
        "##**Changing Numeric Variable to Categorical**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3TLszP9xTbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['CityIdentifier'] = train['CityIdentifier'].astype('category')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HIJo4ZbxcUe",
        "colab_type": "text"
      },
      "source": [
        "##**splitting into Training and Testing Sets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKBoiixJ01Fl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 6000, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfnPsmBq4WuT",
        "colab_type": "text"
      },
      "source": [
        "##**Graphing the Distribution of Binary Variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XphWVnFQ4cNW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['TARGET'].astype(int).plot.hist();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsmlO8Ti4hf8",
        "colab_type": "text"
      },
      "source": [
        "##**Encoding Categorical Variables**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ2LcPzm5Lto",
        "colab_type": "text"
      },
      "source": [
        "If a variable has 2 categories we use label encoding. Otherwise we use one-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnNF711P5Y8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://www.kaggle.com/willkoehrsen/start-here-a-gentle-introduction\n",
        "\n",
        "le = LabelEncoder()\n",
        "le_count = 0\n",
        "\n",
        "# Iterate through the columns\n",
        "for col in app_train:\n",
        "    if app_train[col].dtype == 'object':\n",
        "        # If 2 or fewer unique categories\n",
        "        if len(list(app_train[col].unique())) <= 2:\n",
        "            # Train on the training data\n",
        "            le.fit(app_train[col])\n",
        "            # Transform both training and testing data\n",
        "            app_train[col] = le.transform(app_train[col])\n",
        "            app_test[col] = le.transform(app_test[col])\n",
        "            \n",
        "            # Keep track of how many columns were label encoded\n",
        "            le_count += 1\n",
        "            \n",
        "print('%d columns were label encoded.' % le_count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-e4JrrV5rU3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one-hot encoding of categorical variables\n",
        "app_train = pd.get_dummies(app_train)\n",
        "app_test = pd.get_dummies(app_test)\n",
        "\n",
        "print('Training Features shape: ', app_train.shape)\n",
        "print('Testing Features shape: ', app_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ja8eJPlm51mG",
        "colab_type": "text"
      },
      "source": [
        "One hot encoding can cause the testing and training set to have different number of variables. So we must reconcile that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSKs5l0y5-Zz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = app_train['TARGET']\n",
        "\n",
        "# Align the training and testing data, keep only columns present in both dataframes\n",
        "app_train, app_test = app_train.align(app_test, join = 'inner', axis = 1)\n",
        "\n",
        "# Add the target back in\n",
        "app_train['TARGET'] = train_labels\n",
        "\n",
        "print('Training Features shape: ', app_train.shape)\n",
        "print('Testing Features shape: ', app_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvMiwBJg7Svl",
        "colab_type": "text"
      },
      "source": [
        "##**Repllacing a specific value in a column with NaN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfbyacSM7Xdz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "app_train['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xCXb9DO7Zgj",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f-ImCIf7Z5t",
        "colab_type": "text"
      },
      "source": [
        "##**Finding Correlations between Y and the X values**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIaYlNb07wYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Find correlations with the target and sort\n",
        "correlations = app_train.corr()['TARGET'].sort_values()\n",
        "\n",
        "# Display correlations\n",
        "print('Most Positive Correlations:\\n', correlations.tail(15))\n",
        "print('\\nMost Negative Correlations:\\n', correlations.head(15))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0agp1RX7-uG",
        "colab_type": "text"
      },
      "source": [
        "##**Bar Plot of a Variable**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDr5Y13D8Cvx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the style of plots\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "# Plot the distribution of ages in years\n",
        "plt.hist(app_train['DAYS_BIRTH'] / 365, edgecolor = 'k', bins = 25)\n",
        "plt.title('Age of Client'); plt.xlabel('Age (years)'); plt.ylabel('Count');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQ1i6_olDHw5",
        "colab_type": "text"
      },
      "source": [
        "##**kernel density estimation plot (KDE) of a Variable**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cheMzuhMDPu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize = (10, 8))\n",
        "\n",
        "# KDE plot of loans that were repaid on time\n",
        "sns.kdeplot(app_train.loc[app_train['TARGET'] == 0, 'DAYS_BIRTH'] / 365, label = 'target == 0')\n",
        "\n",
        "# KDE plot of loans which were not repaid on time\n",
        "sns.kdeplot(app_train.loc[app_train['TARGET'] == 1, 'DAYS_BIRTH'] / 365, label = 'target == 1')\n",
        "\n",
        "# Labeling of plot\n",
        "plt.xlabel('Age (years)'); plt.ylabel('Density'); plt.title('Distribution of Ages');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIbe1SK0HG7N",
        "colab_type": "text"
      },
      "source": [
        "##**Imputing Missing Values, and Normalizing Features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDMYJJDnHL9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, Imputer\n",
        "\n",
        "# Drop the target from the training data\n",
        "if 'TARGET' in app_train:\n",
        "    train = app_train.drop(columns = ['TARGET'])\n",
        "else:\n",
        "    train = app_train.copy()\n",
        "    \n",
        "# Feature names\n",
        "features = list(train.columns)\n",
        "\n",
        "\n",
        "# Copy of the testing data\n",
        "test = app_test.copy()\n",
        "\n",
        "# Median imputation of missing values\n",
        "imputer = Imputer(strategy = 'median')\n",
        "\n",
        "# Scale each feature to 0-1\n",
        "scaler = MinMaxScaler(feature_range = (0, 1))\n",
        "\n",
        "# Fit on the training data\n",
        "imputer.fit(train)\n",
        "\n",
        "# Transform both training and testing data\n",
        "train = imputer.transform(train)\n",
        "test = imputer.transform(app_test)\n",
        "\n",
        "# Repeat with the scaler\n",
        "scaler.fit(train)\n",
        "train = scaler.transform(train)\n",
        "test = scaler.transform(test)\n",
        "\n",
        "print('Training data shape: ', train.shape)\n",
        "print('Testing data shape: ', test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgqRY0b_hg0y",
        "colab_type": "text"
      },
      "source": [
        "##**Correlation HeatMap**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Vv3TfM2hkUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ext_data = app_train[['TARGET', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']]\n",
        "ext_data_corrs = ext_data.corr()\n",
        "\n",
        "plt.figure(figsize = (8, 6))\n",
        "\n",
        "# Heatmap of correlations\n",
        "sns.heatmap(ext_data_corrs, cmap = plt.cm.RdYlBu_r, vmin = -0.25, annot = True, vmax = 0.6)\n",
        "plt.title('Correlation Heatmap');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjvKYWiljBqd",
        "colab_type": "text"
      },
      "source": [
        "##**Pairs Plot**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyIOGAFDjDfu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copy the data for plotting\n",
        "plot_data = ext_data.drop(columns = ['DAYS_BIRTH']).copy()\n",
        "\n",
        "# Add in the age of the client in years\n",
        "plot_data['YEARS_BIRTH'] = age_data['YEARS_BIRTH']\n",
        "\n",
        "# Drop na values and limit to first 100000 rows\n",
        "plot_data = plot_data.dropna().loc[:100000, :]\n",
        "\n",
        "# Function to calculate correlation coefficient between two columns\n",
        "def corr_func(x, y, **kwargs):\n",
        "    r = np.corrcoef(x, y)[0][1]\n",
        "    ax = plt.gca()\n",
        "    ax.annotate(\"r = {:.2f}\".format(r),\n",
        "                xy=(.2, .8), xycoords=ax.transAxes,\n",
        "                size = 20)\n",
        "\n",
        "# Create the pairgrid object\n",
        "grid = sns.PairGrid(data = plot_data, size = 3, diag_sharey=False,\n",
        "                    hue = 'TARGET', \n",
        "                    vars = [x for x in list(plot_data.columns) if x != 'TARGET'])\n",
        "\n",
        "# Upper is a scatter plot\n",
        "grid.map_upper(plt.scatter, alpha = 0.2)\n",
        "\n",
        "# Diagonal is a histogram\n",
        "grid.map_diag(sns.kdeplot)\n",
        "\n",
        "# Bottom is density plot\n",
        "grid.map_lower(sns.kdeplot, cmap = plt.cm.OrRd_r);\n",
        "\n",
        "plt.suptitle('Ext Source and Age Features Pairs Plot', size = 32, y = 1.05);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeGUxNWujWpQ",
        "colab_type": "text"
      },
      "source": [
        "##**Polynomial Features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oShnxPXdjhXx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make a new dataframe for polynomial features\n",
        "poly_features = app_train[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH', 'TARGET']]\n",
        "poly_features_test = app_test[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']]\n",
        "\n",
        "# imputer for handling missing values\n",
        "from sklearn.preprocessing import Imputer\n",
        "imputer = Imputer(strategy = 'median')\n",
        "\n",
        "poly_target = poly_features['TARGET']\n",
        "\n",
        "poly_features = poly_features.drop(columns = ['TARGET'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkXRdjIQjntr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Need to impute missing values\n",
        "poly_features = imputer.fit_transform(poly_features)\n",
        "poly_features_test = imputer.transform(poly_features_test)\n",
        "\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "                                  \n",
        "# Create the polynomial object with specified degree\n",
        "poly_transformer = PolynomialFeatures(degree = 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyHZQmwBjqMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the polynomial features\n",
        "poly_transformer.fit(poly_features)\n",
        "\n",
        "# Transform the features\n",
        "poly_features = poly_transformer.transform(poly_features)\n",
        "poly_features_test = poly_transformer.transform(poly_features_test)\n",
        "print('Polynomial Features shape: ', poly_features.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqJRlCxgjynW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#To get the names of the new polynomial features\n",
        "poly_transformer.get_feature_names(input_features = ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH'])[:15]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iml_-45fkqpX",
        "colab_type": "text"
      },
      "source": [
        "##**Random Forest Variabel Importance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PC9UYA73kvYO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Make the random forest classifier\n",
        "random_forest = RandomForestClassifier(n_estimators = 100, random_state = 50, verbose = 1, n_jobs = -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAaR4xagkyss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train on the training data\n",
        "random_forest.fit(train, train_labels)\n",
        "\n",
        "# Extract feature importances\n",
        "feature_importance_values = random_forest.feature_importances_\n",
        "feature_importances = pd.DataFrame({'feature': features, 'importance': feature_importance_values})\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = random_forest.predict_proba(test)[:, 1]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}